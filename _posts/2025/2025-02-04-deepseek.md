---
layout: post
title: DeepSeek介绍
comments: true
tags: [AI]
---


* [DeepSeek AI](https://github.com/deepseek-ai).
* Unified Multimodal Understanding and Generation Models : [Janus](https://github.com/deepseek-ai/Janus/tree/main).
* [Awesome DeepSeek Integrations](https://github.com/deepseek-ai/awesome-deepseek-integration).
* youtube : [DeepSeek R1 Theory Overview : GRPO + RL + SFT](https://youtu.be/QdEuh2UVbu0?si=qFn33l3LvkE6IwqQ)

<div align="center">    
<img src="https://i.redd.it/jf6vo05hx8ee1.jpeg" width="80%"/>
</div>

# KIMI

> 介绍一下deepseek，将它和其他的AI大模型进行对比。并解释为什么它对全球经济造成如此大的影响。

<details>
  <summary>Kimi thinking https://kimi.moonshot.cn/chat/cuhiql6n3mkbb7m2aqpg</summary>

我先仔细分析了用户的需求，他想了解DeepSeek与其他AI大模型的对比以及DeepSeek对全球经济的影响原因。我明白这个需求后，开始思考如何全面且详细地回答这个问题。<br>
首先，我考虑从技术架构、性能表现、应用场景和用户体验等方面对DeepSeek与其他AI大模型进行对比。我回想起之前搜索到的相关资料，比如DeepSeek采用混合架构，结合深度学习与强化学习技术，而GPT系列基于Transformer架构，Google Gemini是多模态AI模型，Claude注重模型的道德和安全性能。这些信息让我对各模型的技术架构有了清晰的认识。<br>
接着，我思考性能表现方面的对比。我回忆起DeepSeek在语言生成、推理与逻辑能力以及计算效率与资源消耗等方面的表现，以及GPT系列、Google Gemini和Claude在这些方面的特点。我意识到这些性能表现的差异是对比的关键点。<br>
然后，我考虑应用场景的对比。我想到DeepSeek适用于智能客服、内容创作、教育辅助和数据分析等场景，GPT系列在内容创作、代码生成和学术研究等领域表现优异，Google Gemini在多模态任务中表现突出，Claude在需要高安全性和道德标准的场景中表现优异。这些应用场景的差异让我对各模型的适用范围有了更深入的理解。<br>
用户体验方面的对比也让我思考了一番。我回想起DeepSeek的用户界面设计简洁易用，GPT系列的用户界面功能丰富但响应速度较慢，Google Gemini的用户界面注重多模态交互，Claude的用户界面设计简洁但生成速度较慢。这些用户体验的差异让我对各模型的用户友好度有了更清晰的认识。<br>
在思考DeepSeek对全球经济的影响原因时，我从成本效益、竞争加剧与普及率提升以及全球竞争与生产力提升三个方面进行分析。我想到DeepSeek的低成本高效益挑战了传统认知，加剧了市场竞争，推动了AI技术的普及，从而对全球经济产生了积极影响。<br>
我意识到这些分析和对比需要详细地呈现给用户，让他能够清晰地了解DeepSeek与其他AI大模型的差异以及DeepSeek对全球经济的影响。现在，我认为已经思考得比较充分了，可以开始正式回复用户了。

</details>

<p></p>

## DeepSeek与其他AI大模型的对比
<p></p>

* 技术架构 ：
  * DeepSeek ：采用<u>混合架构，结合深度学习与强化学习技术</u>，注重高效性和灵活性，支持快速迭代和定制化开发，训练数据选择上更注重多样性和实用性 。
  * GPT 系列 ：基于<u>Transformer架构</u>，以强大的语言生成能力和上下文理解能力著称，参数量大，对计算资源消耗高 。
  * Google Gemini ：<u>多模态AI模型</u>，能处理<u>文本、图像和音频等多种数据类型</u>，架构注重多模态融合，纯文本任务表现略逊于 GPT 系列 。
  * Anthropic Claude ：以 “对齐性” 为核心设计理念，注重模型的<u>道德和安全性能</u>，推理任务中表现中规中矩，生成内容更谨慎可靠 。
* 性能表现 ：
  * 语言理解与生成能力 ：DeepSeek 在语言生成任务中表现出色，尤其在中文语境下优于 GPT 系列，生成文本更符合中文表达习惯，多轮对话连贯性高；GPT-4 英文任务表现优异，但处理中文时偶有语义偏差或文化背景理解不足；Gemini 多模态任务突出，纯文本生成任务略逊；Claude 生成内容安全性优异，但复杂语言任务灵活性和创造力不足 。
  * 推理与逻辑能力 ：DeepSeek 在逻辑推理任务中表现稳定，能处理复杂数学问题和逻辑推理任务；GPT-4 推理任务较强，但有 “幻觉” 问题；Gemini 多模态推理任务表现优异，纯文本推理任务稍显不足；Claude 推理任务中规中矩 。
  * 计算效率与资源消耗 ：DeepSeek 计算效率高，模型设计优化了资源消耗，适合资源有限环境部署；GPT-4 和 Gemini 模型规模大，对计算资源需求高，部署成本高；Claude 计算效率较好，但生成速度略慢于 DeepSeek 。
* 应用场景 ：
  * DeepSeek ：适用于智能客服、内容创作、教育辅助和数据分析等多种场景，在企业级应用中优势大 。
  * GPT 系列 ：在内容创作、代码生成和学术研究等领域表现优异，但高昂部署成本限制了在中小企业中的应用 。
  * Google Gemini ：在多模态任务如图像描述、视频分析中表现突出，适合用于多媒体内容生成和分析 。
  * Anthropic Claude ：在需要高安全性和道德标准的场景如法律咨询、医疗辅助中表现优异，但应用范围相对较窄 。
* 用户体验 ：
  * DeepSeek ：用户界面设计简洁易用，支持多种语言和定制化功能，用户体验较好 。
  * GPT 系列 ：用户界面功能丰富，但模型规模大，响应速度较慢 。
  * Google Gemini ：用户界面注重多模态交互，纯文本任务用户体验稍显不足 。
  * Anthropic Claude ：用户界面设计简洁，但生成速度较慢，可能影响用户体验 。

## DeepSeek对全球经济造成的影响
<p></p>

* **成本效益优势** ：DeepSeek 以远低于现有模型的成本实现了相似的性能，打破了 “模型规模扩大 → 算力需求指数增长” 的传统路径，其训练成本和推理成本大幅降低，如 DeepSeek - R1 的预训练费用仅为 557.6 万美元，推理成本仅为 GPT - 4 Turbo 的 1/70 。这种低成本高效益的模型使得更多企业和开发者能够涉足 AI 领域，推动了 AI 技术的普及和应用，进而影响了全球经济格局。
  1. AI竞争不再是GPU算力，也包含了计算**效率**。
  2. 美国针对中国的**AI芯片**限制不再那么有效果了。
* **开源策略推动** ：DeepSeek 采用开源策略，降低了用户的使用门槛，吸引了大量开发者和研究人员的关注，促进了 AI 开发者社区的协作生态 。这种开源模式推动了 AI 技术的快速发展和创新，加速了 AI 技术在全球范围内的传播和应用，对全球经济产生了深远影响。
* **市场竞争加剧** ：DeepSeek 的出现加剧了 AI 市场的竞争，促使其他 AI 企业和科技巨头加大研发投入，提升自身技术实力和产品性能 。这种竞争不仅推动了 AI 技术的不断进步，也促使企业优化资源配置，提高生产效率，从而对全球经济产生了积极的推动作用。
  * AI的竞争不仅仅是公司间的，可能扩展到<u>国家之间的竞争</u>，和不同AI训练方法之间。
* **全球普及率提升** ：DeepSeek 的低成本和高性能优势，以及开源策略带来的技术普及，使得 AI 技术在全球范围内的普及率显著提升 。随着 AI 技术在更多国家和地区的广泛应用，其对全球经济的贡献也不断增加，推动了全球经济的数字化转型和升级。
* **生产力提升** ：DeepSeek 在自然语言处理、计算机视觉、机器学习等领域的强大实力，使其能够为企业和组织提供更高效、更智能的解决方案 。通过应用 DeepSeek 技术，企业可以提高生产效率，优化业务流程，降低成本，从而提升整体生产力，对全球经济的增长产生了积极影响。

# Install & Run DeepSeek locally

[DeepSeek R1 Locally With Ollama](https://www.datacamp.com/tutorial/deepseek-r1-ollama)

* Install [Ollama](https://ollama.com) `curl -fsSL https://ollama.com/install.sh | sh`
  * Install [Ollama in Nvidia](https://www.jetson-ai-lab.com/tutorial_ollama.html) (Jetson Xavier NX needs [Jetpack 5](https://developer.nvidia.com/embedded/jetpack-sdk-502), [get started](https://developer.nvidia.com/embedded/learn/get-started-jetson-xavier-nx-devkit)).
    * `docker run --runtime nvidia --rm --network=host -v ~/ollama:/ollama -e OLLAMA_MODELS=/ollama dustynv/ollama:r36.2.0`
  * Check install with `ollama -v`
* Run [DeepSeek R1 Model](https://ollama.com/library/deepseek-r1) `ollama run deepseek-r1:8b`
* Running DeepSeek-R1 in the background `ollama serve`

本地部署的优势
* **离线可用性**：在汽车等移动场景中，网络信号可能不稳定，本地部署的模型可以在没有网络的情况下正常工作，确保服务的连续性。
* **低延迟**：本地计算可以避免网络传输带来的延迟，提供更快速的响应，这对于实时性要求高的应用（如自动驾驶辅助系统）至关重要。
* **数据隐私和安全性**：在本地处理数据可以避免数据上传到云端，保护用户的隐私和敏感信息。
* **高可靠性**：在恶劣环境下（如信号不佳的偏远地区），本地部署的系统不会因为网络问题而失效，确保系统的可靠性。
